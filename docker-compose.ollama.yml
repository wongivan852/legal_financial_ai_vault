version: '3.8'

# Docker Compose configuration for Legal AI Vault with Ollama
# This configuration uses local Ollama installation instead of vLLM

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: legal-ai-postgres
    environment:
      POSTGRES_DB: legal_ai_vault
      POSTGRES_USER: ${DATABASE_USER:-legal_ai}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER:-legal_ai}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:v1.8.0
    container_name: legal-ai-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      QDRANT__SERVICE__GRPC_PORT: 6334
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:6333/"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: legal-ai-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # FastAPI Application
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: legal-ai-api
    environment:
      # Application
      APP_NAME: Legal AI Vault
      VERSION: 1.0.0
      DEBUG: ${DEBUG:-false}
      ENVIRONMENT: ${ENVIRONMENT:-production}

      # Security
      JWT_SECRET: ${JWT_SECRET}
      JWT_ALGORITHM: HS256
      ACCESS_TOKEN_EXPIRE_MINUTES: 60
      ENCRYPTION_KEY: ${ENCRYPTION_KEY}

      # Database
      DATABASE_URL: postgresql://${DATABASE_USER:-legal_ai}:${DATABASE_PASSWORD}@postgres:5432/legal_ai_vault

      # Vector Database
      QDRANT_HOST: qdrant
      QDRANT_PORT: 6333

      # Inference Backend
      INFERENCE_BACKEND: ollama

      # Ollama Configuration (connects to host Ollama)
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      OLLAMA_CONTRACT_MODEL: ${OLLAMA_CONTRACT_MODEL:-qwen2.5:14b}
      OLLAMA_COMPLIANCE_MODEL: ${OLLAMA_COMPLIANCE_MODEL:-qwen2.5:14b}
      OLLAMA_ROUTER_MODEL: ${OLLAMA_ROUTER_MODEL:-qwen2.5:7b}
      OLLAMA_RESEARCH_MODEL: ${OLLAMA_RESEARCH_MODEL:-qwen2.5:14b}
      OLLAMA_EMBEDDING_MODEL: ${OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}

      # File Storage
      DOCUMENT_STORAGE_PATH: /data/documents
      MAX_UPLOAD_SIZE_MB: 100

      # Redis
      REDIS_HOST: redis
      REDIS_PORT: 6379

      # CORS
      ALLOWED_ORIGINS: ${ALLOWED_ORIGINS:-http://localhost:3000}

      # Audit Logging
      AUDIT_LOG_RETENTION_DAYS: 2555

      # Inference Settings
      DEFAULT_MAX_TOKENS: 4096
      DEFAULT_TEMPERATURE: 0.3
      INFERENCE_TIMEOUT_SECONDS: 300
    volumes:
      - ./data/documents:/data/documents
      - ./logs:/app/logs
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"  # Allows container to access host Ollama
    restart: unless-stopped
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4

  # Nginx Reverse Proxy
  nginx:
    image: nginx:1.24-alpine
    container_name: legal-ai-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - api
    restart: unless-stopped

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: legal-ai-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alerts:/etc/prometheus/alerts:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=90d'
    restart: unless-stopped

  # Grafana Dashboards
  grafana:
    image: grafana/grafana:10.1.0
    container_name: legal-ai-grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    restart: unless-stopped

volumes:
  postgres_data:
    driver: local
  qdrant_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  default:
    name: legal-ai-network
    driver: bridge
